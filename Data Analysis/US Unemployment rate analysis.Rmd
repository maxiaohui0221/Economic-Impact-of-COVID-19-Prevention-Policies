---
title: "US_Unemployment_rate_analysis"
author: "Xiaohui Ma"
date: "2024-11-08"
output:
  pdf_document: default
  html_document: default
  word_document: default
editor_options:
  markdown:
    wrap: 72
---

#install and library package
```{r}
library(RColorBrewer)
library(ggplot2)
library(gridExtra)
#install.packages("maps")
library(maps)
library(tigris)
library(dplyr)
```


## The Data

```{r}
us_unemployment <- read.csv("/Users/maxiaohui/Desktop/Honor Capstone project 2024-25/Honor project data/Unemployment Rate/us_unemployment_combine.csv")
head(us_unemployment)

```

```{r}
summary(us_unemployment)
```

```{r}
us_unemployment$Year <- as.factor(us_unemployment$Year)
str(us_unemployment)
```

## Variables:

Response(dependent variable): -Unemployment rate of U.S.

Predictors(independent variables): -state -school closing -workplace
closing -cancel public event -restriction gathering -close public
transport -state at home requirement -restrictions on internal movement

```{r}
colSums(is.na(us_unemployment))
```
No missing values in the data.

##EDA: Distribution of response variables
```{r}

r <- ggplot(us_unemployment, aes(x=Unemployment.Rate  )) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of Unemployment.Rate in US ", x="Unemployment.Rate  ", y="Count") +
  theme_minimal()
r

```



## EDA: Distribution of predictors 

```{r}

p1 <- ggplot(us_unemployment, aes(x=School.closing)) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of School.closing", x="School.closing", y="Count") +
  theme_minimal()
p2 <- ggplot(us_unemployment, aes(x=Workplace.closing)) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of Workplace.closing", x="Workplace.closing", y="Count") +
  theme_minimal()
p3 <- ggplot(us_unemployment, aes(x=Cancel.public.event)) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of Cancel.public.event ", x="Cancel.public.event ", y="Count") +
  theme_minimal()
p4 <- ggplot(us_unemployment, aes(x=Restriction.on.gathering)) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of Restriction.on.gathering", x="Restriction.on.gathering", y="Count") +
  theme_minimal()
p5 <- ggplot(us_unemployment, aes(x=Close.public.transport)) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of Close.public.transport", x="Close.public.transport", y="Count") +
  theme_minimal()
p6 <- ggplot(us_unemployment, aes(x=State.at.home.requirement )) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of State.at.home.requirement ", x="State.at.home.requirement ", y="Count") +
  theme_minimal()
p7 <- ggplot(us_unemployment, aes(x=Restrictions.on.internal.movement)) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of internal.movement control", x="Restrictions.on.internal.movement", y="Count") +
  theme_minimal()
p8 <- ggplot(us_unemployment, aes(x=International.travel.control )) +
  geom_histogram(fill="lightblue",color="black",bins=20) +
  labs(title="Distribution of International control ", x="International.travel.control", y="Count") +
  theme_minimal()

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol= 2)

```


## EDA: Response Vs. Predictors

```{r}
library("ggplot2") 
library("gridExtra")

s1<-ggplot(us_unemployment, aes(x=School.closing, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s2<-ggplot(us_unemployment, aes(x=Year, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s3<-ggplot(us_unemployment, aes(x=Month, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s4<-ggplot(us_unemployment, aes(x=Workplace.closing, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s5<-ggplot(us_unemployment, aes(x=Cancel.public.event, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s6<-ggplot(us_unemployment, aes(x=Restriction.on.gathering, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s7<-ggplot(us_unemployment, aes(x=Close.public.transport, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s8<-ggplot(us_unemployment, aes(x=State.at.home.requirement, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s9<-ggplot(us_unemployment, aes(x=Restrictions.on.internal.movement, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()
s10<-ggplot(us_unemployment, aes(x=International.travel.control, y=Unemployment.Rate)) + geom_point(alpha = 0.5, size = 1.5) + theme_minimal()


grid.arrange(s1, s2,s3,s4, s5, s6, s7, s8,s9, s10, ncol = 3, nrow = 4)
```
There are positive relationships between US unemployment rate and all response variables except with international travel control


```{r}
library(ggforce)

ggplot(data = us_unemployment) +
geom_point(mapping = aes(x = Month, y = Unemployment.Rate, color = Year)) +
facet_wrap_paginate(~ State, nrow = 4, ncol = 4, page = 1)

pdf("unemployment_by_state.pdf", width = 12, height = 10)
for (i in 1:4) {
  print(
    ggplot(us_unemployment, aes(x = Month, y = Unemployment.Rate, color = Year)) +
      geom_point() +
      facet_wrap_paginate(~ State, nrow = 4, ncol = 4, page = i) +
      ggtitle(paste("Page", i))
  )
}
dev.off()
```

```{r}
# Scatterplot for Month vs Unemployment rate with color based on Year and State
library(ggplot2)
library(dplyr)

selected_states <- c("California")

filtered_data <- us_unemployment %>%
  filter(State %in% selected_states)

ggplot(data = filtered_data) +
geom_point(mapping = aes(x = Month, y = Unemployment.Rate, color = Year, line = Year),size = 3) +
  scale_color_manual(values = c("2019" = "#FF7F50", "2020" = "#3CB371", "2021" = "#87CEEB", "2022" = "#DA70D6")) +
  labs(title = "California")+ 
  theme(text = element_text(size = 14))

pdf("unemployment_california.pdf", width = 12, height = 10)
  print(ggplot(data = filtered_data) +
geom_point(mapping = aes(x = Month, y = Unemployment.Rate, color = Year), size = 6) +
  scale_color_manual(values = c("2019" = "#FF7F50", "2020" = "#3CB371", "2021" = "#87CEEB", "2022" = "#DA70D6")) +
 theme(text = element_text(size = 30)))
  
dev.off()

ggplot(us_unemployment, aes(x = Month, y = Unemployment.Rate, color = factor(Year))) +
  geom_point() +
  geom_smooth(mapping = aes(linetype = factor(Year))) +
  #geom_smooth(method = "loess", se = FALSE, color = "red") +
  labs(title = "US Unemplyment rate vs Month (Colored by Year)", 
       x = "Month", 
       y = "Unemplyment rate") +
  theme_minimal() +
  scale_color_manual(values = brewer.pal(n = 4, name = "Set2"))

#New York City
selected_states2 <- c("New York city")

filtered_data2 <- us_unemployment %>%
  filter(State %in% selected_states2)

ggplot(data = filtered_data2) +
geom_point(mapping = aes(x = Month, y = Unemployment.Rate, color = Year, line = Year),size = 3) +
  scale_color_manual(values = c("2019" = "#FF7F50", "2020" = "#3CB371", "2021" = "#87CEEB", "2022" = "#DA70D6")) +
  labs(title = "New York City Unemployment Rate")+ 
  theme(text = element_text(size = 14))

pdf("unemployment_nyc.pdf", width = 12, height = 10)
  print(ggplot(data = filtered_data) +
geom_point(mapping = aes(x = Month, y = Unemployment.Rate, color = Year), size = 6) +
  scale_color_manual(values = c("2019" = "#FF7F50", "2020" = "#3CB371", "2021" = "#87CEEB", "2022" = "#DA70D6")) +
 theme(text = element_text(size = 30)))
  
dev.off()

```
The trend in the chart shows a nonlinear, inverted-U pattern, and a quadratic function could potentially be used to approximate it 

```{r}
selected_states2 <- c("California", "Alaska", "New York", "Illinois")

filtered_data2 <- us_unemployment %>%
  filter(State %in% selected_states2)

ggplot(filtered_data2, aes(x = School.closing, y = Unemployment.Rate, color = State)) +
  geom_point() +
  #geom_smooth(method = "lm", se = F) +
  #geom_smooth(mapping = aes(linetype = State)) +
  geom_smooth(method = "loess", se = FALSE, color = "red") +
  labs(title = "Unemplyment rate vs Month (Colored by State)", 
       x = "School.closing", 
       y = "Unemplyment rate") +
  theme_minimal() +
  scale_color_manual(values = brewer.pal(n = 4, name = "Set2"))
```
```{r}
ggplot(us_unemployment, aes(x = State.at.home.requirement, y = Unemployment.Rate)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  labs(title = "US Unemplyment rate vs State.at.home.requirement", 
       x = "State.at.home.requirement", 
       y = "Unemplyment rate") +
  theme_minimal() 
```

```{r}
ggplot(us_unemployment, aes(x = International.travel.control, y = Unemployment.Rate)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  labs(title = "US Unemplyment rate vs International.travel.control", 
       x = "International.travel.control", 
       y = "Unemplyment rate") +
  theme_minimal()
```


```{r}
us_unemployment$SchoolClosingGroup <- cut(
  us_unemployment$ School.closing,
  breaks = 3, 
  labels = c("Low", "Medium", "High"),
  include.lowest = TRUE
)

ggplot(us_unemployment , aes(x = Workplace.closing, y = Unemployment.Rate, color = SchoolClosingGroup)) +
  geom_point() +
  labs(title = "Unemplyment rate vs Workplace.closing (Colored by School cosing)", 
       x = "Workplace closing", 
       y = "Unemplyment rate") +
  theme_minimal()

pdf("unemployment vs workplace closing.pdf", width = 12, height = 10)
  print(
    ggplot(us_unemployment , aes(x = Workplace.closing, y = Unemployment.Rate, color = SchoolClosingGroup)) +
  geom_point(size = 2) +
  labs( x = "Workplace closing", y = "unemployment rate") +
  theme_minimal()+
  theme(text = element_text(size = 20))
)
dev.off()
```
Different slope shows that there might be interaction effect between school closing and workplace closing. 

## EDA: Correlation check
```{r}
# Install and load the ggcorrplot package
library(ggcorrplot)


reduced_data <- subset(us_unemployment, select = c(School.closing, Workplace.closing,  Cancel.public.event, Restriction.on.gathering, Close.public.transport,State.at.home.requirement, Restrictions.on.internal.movement, International.travel.control))

# Compute correlation at 2 decimal places
corr_matrix = round(cor(reduced_data), 2)

# Compute and show the  result
ggcorrplot(corr_matrix, hc.order = TRUE, type = "lower",
          lab = TRUE)

```
There are some significant positive correlation between the numerical variables. For example: cancel public event and workplace closing, cancel public event and restriction on gathering, workplace closing and restriction on gathering, 

## Model Selection

### model base

```{r}
library("car")
library(MASS)

#defining variables for easier model fitting
x1 <- us_unemployment$State
x2 <- us_unemployment$Year
x3 <- us_unemployment$Month
x4 <- us_unemployment$School.closing
x5 <- us_unemployment$Workplace.closing
x6 <- us_unemployment$Cancel.public.event
x7 <-  us_unemployment$Restriction.on.gathering
x8 <- us_unemployment$Close.public.transport
x9 <- us_unemployment$State.at.home.requirement
x10 <- us_unemployment$Restrictions.on.internal.movement
x11 <- us_unemployment$International.travel.control

model_base <- lm(Unemployment.Rate ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11, data = us_unemployment)

summary(model_base)

vif(model_base)


```

### model 1 (full model with all interaction and quadratic term)

```{r}

model_1 <- lm(Unemployment.Rate ~ (x1 + x2 + x3 + x4 + x5 +x6 + x7 + x8 + x9 + x10 + x11)^2 + I(x3^2) + I(x4^2) + I(x5^2) + I(x6^2) + I(x7^2) + I(x8^2) + I(x9^2) + I(x10^2) + I(x11^2), data = us_unemployment)

summary(model_1)
```
Try to delete non-significant square terms(I(x6^2), I(x7^2), I(x11^2)) first, and then delete non-significant main predictors. (making simpler model )

### model 2 (reduce quadratic terms)

```{r}
model_2 <- lm(Unemployment.Rate ~ (x1 + x2 + x3 + x4 + x5 +x6 + x7 + x8 + x9 + x10 + x11)^2 + I(x3^2) + I(x9^2) + I(x10^2) + I(x11^2), data = us_unemployment)

summary(model_2)

```


### model 3 (reduce interaction terms)
```{r}

model_3 <- lm(Unemployment.Rate ~ x1 + x2 + x3 + x4 + x5 +x6 + x7 + x8 + x9 + x10 + x11  + x3:x4  + x4:x5  + x8:x10 + I(x3^2) + I(x9^2) +I(x10^2) , data = us_unemployment)

summary(model_3)

```
### model 4 (reduce predictor terms)
```{r}
model_4 <- lm(Unemployment.Rate ~ x1 + x2 + x3 + x4 + x5 +x6 + x8 + x9 + x10 + x11  + x3:x4  + x4:x5  + x8:x10 + I(x3^2) + I(x9^2) +I(x10^2) , data = us_unemployment)

summary(model_4)

AIC(model_1, model_2, model_3, model_4)
```

## Residual Analysis

```{r}
par(mfrow = c(2, 2))
plot(model_4)
```
According to Fitted vs. Residuals plot, there is an sort of megaphone shape appearing, which suggest that variance is increasing. Also, the red line in the plot is fairly flat indicating the linearity assumption is met.  Also, there is no clear trend, which suggest that the independence assumption is met. 

According to the qq plot, some data at the head and tail doesn't on the line. 

According to the Scale-Location plot, the increasing trend also shows increasing variance.

 

### Checking Linearity and Constant Variance

```{r}

plot_data2 <- data.frame(fitted = fitted(model_4), residuals = resid(model_4))

library(ggplot2)
ggplot(data = plot_data2, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Predicted values", y = "Residuals")
```

### Checking Normality Assumption

```{r}
qqnorm(resid(model_4))
qqline(resid(model_4))

shapiro.test(resid(model_4))
```

p-value < 2.2e-16 < 0.05, Reject, and suggest that residuals not appear to be normally distributed.

### Checking Independence

```{r}
library(car)
dwt(model_4)
```

p-value = 0 < 0.05  Reject, and suggest that residuals are not
all independent


### model 5 (take log transformation)

x1 <- us_unemployment$State
x2 <- us_unemployment$Year
x3 <- us_unemployment$Month
x4 <- us_unemployment$School.closing
x5 <- us_unemployment$Workplace.closing
x6 <- us_unemployment$Cancel.public.event
x7 <-  us_unemployment$Restriction.on.gathering
x8 <- us_unemployment$Close.public.transport
x9 <- us_unemployment$State.at.home.requirement
x10 <- us_unemployment$Restrictions.on.internal.movement
x11 <- us_unemployment$International.travel.control
```{r}
model_5 <- lm(log(Unemployment.Rate) ~ x1 + x2 + x3 + x4 + x5 +x6 + x8 + x9 + x10 + x11 + x4:x5  + x8:x10 + I(x3^2) + I(x9^2) +I(x10^2) , data = us_unemployment)

summary(model_5)

```
###Checking Linearity and Constant Variance
```{r}
plot_data3 <- data.frame(fitted = fitted(model_5), residuals = resid(model_5))

library(ggplot2)
ggplot(data = plot_data3, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Predicted values", y = "Residuals")

```

```{r}
original_data <- model.frame(model_5)

original_data$fitted <- fitted(model_5)
original_data$residuals <- resid(model_5)

high_resid <- subset(original_data, abs(residuals) > 0.5)
high_resid

original_data$high_resid_flag <- abs(original_data$residual) > 0.5

ggplot(original_data, aes(x = fitted, y = residuals, color = high_resid_flag)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Predicted values", y = "Residuals") +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "blue"))
```
#Check independece
```{r}
#install.packages("lmtest")      
library(lmtest)
library(car)
dwtest(model_5)
```

p-value = 0 < 2.2e-16 <0.05 Fail to Reject, and suggest that residuals are not
all independence

#Check normality

```{r}
qqnorm(resid(model_5))
qqline(resid(model_5))

shapiro.test(resid(model_5))
```
p-value < 2.2e-16 < 0.05, Reject, and suggest that residuals not appear to be normally distributed.

Normality and independence assumption are still violated.


```{r}

```


```{r}
#Download US state borders with polygonal geometry
states_sf2 <- states(cb = TRUE, resolution = "20m", year = 2024)

glimpse(states_sf2)
head(states_sf2)

#find the different data
setdiff(states_sf2$NAME, us_unemployment$State)
setdiff(us_unemployment$State, states_sf2$NAME)

#delete extra states
states_sf_clean3 <- states_sf2 %>%
  filter(!(NAME %in% c("Puerto Rico")))

us_unemp_clean <- us_unemployment %>%
  filter(!(State %in% c("Los Angeles County", "New York city")))

us_unemp_clean$residuals <- residuals(model_5)

# average residual by states
average_residual_by_state_us <- aggregate(residuals ~ State, data = us_unemp_clean, FUN = mean)

average_residual_by_state_us


# Create the neighbor list
neighbor_list <- poly2nb(states_sf_clean3)

# Create a spatial weights matrix
weights2 <- nb2listw(neighbor_list, style = "W", zero.policy = TRUE)  # W for row-standardized weights


# left join US unemployment_combine data with state_sf

us_unemp_nb <- left_join(average_residual_by_state_us, states_sf_clean3, by=c("State" = "NAME"))
head(us_unemp_nb)

# try Moran's test 
moran.test(average_residual_by_state_us$residuals, weights2, na.action = na.omit, zero.policy = TRUE)


```
```
























